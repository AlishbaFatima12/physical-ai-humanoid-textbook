"use strict";(globalThis.webpackChunkphysical_ai_humanoid_textbook=globalThis.webpackChunkphysical_ai_humanoid_textbook||[]).push([[4195],{8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var r=i(6540);const s={},a=r.createContext(s);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(a.Provider,{value:n},e.children)}},9610:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"chapter-6-isaac-perception","title":"Chapter 6: NVIDIA Isaac Perception","description":"Master perception skills with NVIDIA Isaac Sim. Build VSLAM, object detection, and synthetic data generation pipelines. First Layer 3 chapter - create reusable perception skills.\\n","source":"@site/docs/006-chapter-6-isaac-perception.md","sourceDirName":".","slug":"/chapter-6-isaac-perception","permalink":"/physical-ai-humanoid-textbook/docs/chapter-6-isaac-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/AlishbaFatima12/physical-ai-humanoid-textbook/edit/main/docs/docs/006-chapter-6-isaac-perception.md","tags":[{"inline":true,"label":"layer3","permalink":"/physical-ai-humanoid-textbook/docs/tags/layer-3"},{"inline":true,"label":"isaac","permalink":"/physical-ai-humanoid-textbook/docs/tags/isaac"},{"inline":true,"label":"perception","permalink":"/physical-ai-humanoid-textbook/docs/tags/perception"},{"inline":true,"label":"skills","permalink":"/physical-ai-humanoid-textbook/docs/tags/skills"}],"version":"current","lastUpdatedBy":"AlishbaFatima12","lastUpdatedAt":1764391712000,"sidebarPosition":6,"frontMatter":{"id":"chapter-6-isaac-perception","title":"Chapter 6: NVIDIA Isaac Perception","sidebar_position":6,"description":"Master perception skills with NVIDIA Isaac Sim. Build VSLAM, object detection, and synthetic data generation pipelines. First Layer 3 chapter - create reusable perception skills.\\n","keywords":["Isaac Sim","VSLAM","perception","synthetic data","domain randomization","reusable skills"],"tags":["layer3","isaac","perception","skills"]},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Unity Visualization","permalink":"/physical-ai-humanoid-textbook/docs/chapter-5-unity-visualization"},"next":{"title":"Chapter 7: Path Planning & Reinforcement Learning","permalink":"/physical-ai-humanoid-textbook/docs/chapter-7-path-planning-rl"}}');var s=i(4848),a=i(8453);const t={id:"chapter-6-isaac-perception",title:"Chapter 6: NVIDIA Isaac Perception",sidebar_position:6,description:"Master perception skills with NVIDIA Isaac Sim. Build VSLAM, object detection, and synthetic data generation pipelines. First Layer 3 chapter - create reusable perception skills.\n",keywords:["Isaac Sim","VSLAM","perception","synthetic data","domain randomization","reusable skills"],tags:["layer3","isaac","perception","skills"]},l="Chapter 6: NVIDIA Isaac Perception",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Why NVIDIA Isaac Sim?",id:"why-nvidia-isaac-sim",level:2},{value:"Installing NVIDIA Isaac Sim",id:"installing-nvidia-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Step 1: Download Isaac Sim",id:"step-1-download-isaac-sim",level:3},{value:"Step 2: Install Dependencies",id:"step-2-install-dependencies",level:3},{value:"Step 3: Verify Installation",id:"step-3-verify-installation",level:3},{value:"Isaac Sim Interface Overview",id:"isaac-sim-interface-overview",level:2},{value:"Main Components",id:"main-components",level:3},{value:"USD vs URDF",id:"usd-vs-urdf",level:3},{value:"Creating Your First Isaac Sim Scene",id:"creating-your-first-isaac-sim-scene",level:2},{value:"Example: Humanoid in Warehouse Environment",id:"example-humanoid-in-warehouse-environment",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Domain Randomization for Robustness",id:"domain-randomization-for-robustness",level:3},{value:"Example: Randomized Object Detection Dataset",id:"example-randomized-object-detection-dataset",level:3},{value:"Visual SLAM (VSLAM) with Isaac Sim",id:"visual-slam-vslam-with-isaac-sim",level:2},{value:"What is VSLAM?",id:"what-is-vslam",level:3},{value:"VSLAM Algorithm Options",id:"vslam-algorithm-options",level:3},{value:"Implementing VSLAM with Isaac Sim",id:"implementing-vslam-with-isaac-sim",level:3},{value:"Reusable Perception Skill: Object Detector \u2b50",id:"reusable-perception-skill-object-detector-",level:2},{value:"Skill Interface",id:"skill-interface",level:3},{value:"Skill Testing Protocol",id:"skill-testing-protocol",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Launch Humanoid in Isaac Sim (Easy)",id:"exercise-1-launch-humanoid-in-isaac-sim-easy",level:3},{value:"Exercise 2: Generate Synthetic Dataset (Medium)",id:"exercise-2-generate-synthetic-dataset-medium",level:3},{value:"Exercise 3: Build VSLAM Skill (Hard)",id:"exercise-3-build-vslam-skill-hard",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Reusable Skills Developed",id:"reusable-skills-developed",level:2},{value:"Skill 1: RGB-D Object Detector",id:"skill-1-rgb-d-object-detector",level:3},{value:"Skill 2: VSLAM Localizer",id:"skill-2-vslam-localizer",level:3},{value:"Skill 3: Synthetic Data Generator",id:"skill-3-synthetic-data-generator",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Self-Check: Can You...",id:"self-check-can-you",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-6-nvidia-isaac-perception",children:"Chapter 6: NVIDIA Isaac Perception"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Learning Objectives:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Install and configure NVIDIA Isaac Sim 2023.1.1"}),"\n",(0,s.jsx)(n.li,{children:"Generate synthetic perception data with domain randomization"}),"\n",(0,s.jsx)(n.li,{children:"Implement Visual SLAM (VSLAM) for humanoid localization"}),"\n",(0,s.jsx)(n.li,{children:"Build object detection pipelines using Isaac Sim sensors"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Create reusable perception skills with clear interfaces"})," \u2b50 NEW (Layer 3)"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Prerequisites",type:"info",children:(0,s.jsxs)(n.p,{children:["Complete ",(0,s.jsx)(n.a,{href:"./chapter-5-unity-visualization",children:"Chapter 5"})," - Unity visualization and ROS 2 integration"]})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Duration"}),": 8 hours (lecture + lab)"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Layer Enforcement"}),": This is a ",(0,s.jsx)(n.strong,{children:"Layer 3 (Intelligence Design)"})," chapter. You will build ",(0,s.jsx)(n.strong,{children:"production-grade, reusable perception skills"})," with:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Clear input/output interfaces"}),"\n",(0,s.jsx)(n.li,{children:"Decision trees for failure handling"}),"\n",(0,s.jsx)(n.li,{children:"Measurable performance metrics"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"why-nvidia-isaac-sim",children:"Why NVIDIA Isaac Sim?"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Isaac Sim vs Gazebo"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gazebo"}),": General-purpose robot simulation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac Sim"}),": Specialized for AI/ML perception training with photorealistic rendering"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Features"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"RTX-Accelerated Ray Tracing"}),": Photorealistic lighting and shadows"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Labeled datasets for training perception models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Domain Randomization"}),": Automatic variation in lighting, textures, object poses"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS 2 Integration"}),": Native bridge (no separate connector needed)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac SDK"}),": Pre-built perception gems (VSLAM, object detection, pose estimation)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Use Cases"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Training object detection models without real-world data collection"}),"\n",(0,s.jsx)(n.li,{children:"Testing VSLAM algorithms in diverse environments"}),"\n",(0,s.jsx)(n.li,{children:"Sim-to-real transfer for humanoid navigation"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"installing-nvidia-isaac-sim",children:"Installing NVIDIA Isaac Sim"}),"\n",(0,s.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Minimum"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"GPU: NVIDIA RTX 2070 or better"}),"\n",(0,s.jsx)(n.li,{children:"VRAM: 8GB"}),"\n",(0,s.jsx)(n.li,{children:"RAM: 32GB"}),"\n",(0,s.jsx)(n.li,{children:"OS: Ubuntu 22.04 LTS"}),"\n",(0,s.jsx)(n.li,{children:"Driver: NVIDIA 525+ with Vulkan support"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Verify GPU"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"nvidia-smi\r\n# Check: Driver Version \u2265 525, CUDA Version \u2265 12.0\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-1-download-isaac-sim",children:"Step 1: Download Isaac Sim"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Go to ",(0,s.jsx)(n.a,{href:"https://developer.nvidia.com/isaac-sim",children:"NVIDIA Isaac Sim Downloads"})]}),"\n",(0,s.jsxs)(n.li,{children:["Download ",(0,s.jsx)(n.strong,{children:"Isaac Sim 2023.1.1"})," (Linux)"]}),"\n",(0,s.jsxs)(n.li,{children:["Extract to ",(0,s.jsx)(n.code,{children:"~/nvidia/isaac_sim"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-install-dependencies",children:"Step 2: Install Dependencies"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/nvidia/isaac_sim\r\n./setup_conda.sh\r\nconda activate isaac-sim\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-verify-installation",children:"Step 3: Verify Installation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"./isaac-sim.sh\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected"}),": Isaac Sim GUI opens with default scene."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"isaac-sim-interface-overview",children:"Isaac Sim Interface Overview"}),"\n",(0,s.jsx)(n.h3,{id:"main-components",children:"Main Components"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Viewport"}),": 3D rendered scene (RTX ray tracing)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stage"}),": Hierarchy of USD assets (Universal Scene Description)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Property Panel"}),": Object properties (physics, materials, sensors)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Content Browser"}),": Asset library"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Script Editor"}),": Python scripting (omni.isaac.core)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"usd-vs-urdf",children:"USD vs URDF"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"USD (Universal Scene Description)"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pixar's scene graph format"}),"\n",(0,s.jsx)(n.li,{children:"Supports complex materials, lighting, animations"}),"\n",(0,s.jsx)(n.li,{children:"Native format for Isaac Sim"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Conversion"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# URDF \u2192 USD conversion\r\nfrom omni.isaac.urdf import _urdf\r\nurdf_interface = _urdf.acquire_urdf_interface()\r\nurdf_interface.load_robot("humanoid.urdf", "/World/Humanoid")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"creating-your-first-isaac-sim-scene",children:"Creating Your First Isaac Sim Scene"}),"\n",(0,s.jsx)(n.h3,{id:"example-humanoid-in-warehouse-environment",children:"Example: Humanoid in Warehouse Environment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="scripts/spawn_humanoid_warehouse.py"',children:'"""\r\nPurpose: Spawn humanoid robot in Isaac Sim warehouse for perception testing\r\nPrerequisites: Isaac Sim 2023.1.1, humanoid.urdf\r\nExpected Output: Robot in warehouse with RGB-D camera streaming to ROS 2\r\n"""\r\n\r\nfrom omni.isaac.kit import SimulationApp\r\n\r\n# Launch Isaac Sim\r\nsimulation_app = SimulationApp({"headless": False})\r\n\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.sensor import Camera\r\nimport omni.isaac.core.utils.nucleus as nucleus_utils\r\n\r\ndef main():\r\n    # Create world\r\n    world = World(stage_units_in_meters=1.0)\r\n\r\n    # Add warehouse environment\r\n    warehouse_path = nucleus_utils.get_assets_root_path() + \\\r\n                    "/Isaac/Environments/Simple_Warehouse/warehouse.usd"\r\n    add_reference_to_stage(usd_path=warehouse_path, prim_path="/World/Warehouse")\r\n\r\n    # Load humanoid robot\r\n    robot = world.scene.add(\r\n        Robot(\r\n            prim_path="/World/Humanoid",\r\n            name="humanoid_robot",\r\n            usd_path="humanoid.usd"  # Converted from URDF\r\n        )\r\n    )\r\n\r\n    # Add RGB-D camera to robot head\r\n    camera = Camera(\r\n        prim_path="/World/Humanoid/head/camera",\r\n        position=[0.15, 0, 0.5],  # Front of head\r\n        frequency=30,  # 30 Hz\r\n        resolution=(640, 480)\r\n    )\r\n    camera.initialize()\r\n    camera.add_motion_vectors_to_frame()  # For depth\r\n\r\n    # Reset world\r\n    world.reset()\r\n\r\n    # Simulation loop\r\n    print("Isaac Sim ready. Press Ctrl+C to exit.")\r\n    while simulation_app.is_running():\r\n        world.step(render=True)\r\n\r\n    simulation_app.close()\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Run"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/nvidia/isaac_sim\r\n./python.sh ~/ros2_ws/src/humanoid_perception/scripts/spawn_humanoid_warehouse.py\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,s.jsx)(n.h3,{id:"domain-randomization-for-robustness",children:"Domain Randomization for Robustness"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Concept"}),": Vary environment parameters to train perception models robust to real-world variations."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Randomization Dimensions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Lighting"}),": Intensity, color temperature, direction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Textures"}),": Object materials, floor patterns"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Object Poses"}),": Random positions, orientations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Camera"}),": Exposure, gain, distortion"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-randomized-object-detection-dataset",children:"Example: Randomized Object Detection Dataset"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="scripts/generate_object_dataset.py"',children:'"""\r\nPurpose: Generate 1000 labeled images of objects for detection training\r\nPrerequisites: Isaac Sim with ShapesNet objects\r\nExpected Output: images/ folder with RGB + bounding box annotations\r\n"""\r\n\r\nfrom omni.isaac.kit import SimulationApp\r\nsimulation_app = SimulationApp({"headless": True})  # Headless for speed\r\n\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.objects import DynamicCuboid\r\nfrom omni.isaac.sensor import Camera\r\nfrom omni.replicator.core import Writer, AnnotatorRegistry\r\nimport omni.replicator.core as rep\r\nimport random\r\n\r\ndef main():\r\n    world = World()\r\n\r\n    # Create camera\r\n    camera = Camera(\r\n        prim_path="/World/Camera",\r\n        position=[2.0, 0, 1.5],\r\n        resolution=(1280, 720)\r\n    )\r\n\r\n    # Randomize lighting\r\n    rep.create.light(\r\n        light_type="Dome",\r\n        rotation=rep.distribution.uniform((0, 0, 0), (360, 360, 360)),\r\n        intensity=rep.distribution.uniform(500, 1500)\r\n    )\r\n\r\n    # Randomize objects\r\n    def randomize_scene():\r\n        # Spawn random cubes\r\n        for i in range(random.randint(3, 8)):\r\n            cube = DynamicCuboid(\r\n                prim_path=f"/World/Cube{i}",\r\n                position=[\r\n                    random.uniform(-1, 1),\r\n                    random.uniform(-1, 1),\r\n                    random.uniform(0.5, 2)\r\n                ],\r\n                size=random.uniform(0.1, 0.5),\r\n                color=[random.random(), random.random(), random.random()]\r\n            )\r\n\r\n    # Capture 1000 frames\r\n    with rep.new_layer():\r\n        for frame in range(1000):\r\n            randomize_scene()\r\n            world.step(render=True)\r\n\r\n            # Capture with annotations\r\n            camera.get_rgba()  # Trigger capture\r\n            # Bounding boxes auto-saved by replicator\r\n\r\n            if frame % 100 == 0:\r\n                print(f"Generated {frame}/1000 frames")\r\n\r\n    print("Dataset generation complete!")\r\n    simulation_app.close()\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"visual-slam-vslam-with-isaac-sim",children:"Visual SLAM (VSLAM) with Isaac Sim"}),"\n",(0,s.jsx)(n.h3,{id:"what-is-vslam",children:"What is VSLAM?"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Visual Simultaneous Localization and Mapping"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Localization"}),": Estimate robot's pose (position + orientation)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mapping"}),": Build 3D map of environment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Visual"}),": Uses camera images (not LiDAR)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Use Case"}),": Humanoid navigation in unknown environments without GPS."]}),"\n",(0,s.jsx)(n.h3,{id:"vslam-algorithm-options",children:"VSLAM Algorithm Options"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Algorithm"}),(0,s.jsx)(n.th,{children:"Type"}),(0,s.jsx)(n.th,{children:"Accuracy"}),(0,s.jsx)(n.th,{children:"Speed"}),(0,s.jsx)(n.th,{children:"Use Case"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"ORB-SLAM3"})}),(0,s.jsx)(n.td,{children:"Feature-based"}),(0,s.jsx)(n.td,{children:"High"}),(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"Indoor navigation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"LSD-SLAM"})}),(0,s.jsx)(n.td,{children:"Direct"}),(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"Fast"}),(0,s.jsx)(n.td,{children:"Real-time robotics"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"RTAB-Map"})}),(0,s.jsx)(n.td,{children:"RGB-D"}),(0,s.jsx)(n.td,{children:"High"}),(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"Robots with depth cameras"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"implementing-vslam-with-isaac-sim",children:"Implementing VSLAM with Isaac Sim"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Step 1: Install RTAB-Map"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-rtabmap-ros\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Step 2: Configure Isaac Sim Camera"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="scripts/isaac_vslam_camera.py"',children:'from omni.isaac.sensor import Camera\r\nfrom omni.isaac.ros2_bridge import ROS2Bridge\r\n\r\n# Create RGB-D camera\r\ncamera_rgb = Camera(\r\n    prim_path="/World/Humanoid/head/camera_rgb",\r\n    resolution=(640, 480),\r\n    frequency=30\r\n)\r\n\r\ncamera_depth = Camera(\r\n    prim_path="/World/Humanoid/head/camera_depth",\r\n    resolution=(640, 480),\r\n    frequency=30\r\n)\r\ncamera_depth.add_distance_to_image_plane_to_frame()  # Depth\r\n\r\n# Bridge to ROS 2\r\nbridge = ROS2Bridge()\r\nbridge.create_camera_publishers(\r\n    camera_rgb,\r\n    topic_name="/camera/color/image_raw",\r\n    frame_id="camera_link"\r\n)\r\nbridge.create_camera_publishers(\r\n    camera_depth,\r\n    topic_name="/camera/depth/image_raw",\r\n    frame_id="camera_link"\r\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Step 3: Launch RTAB-Map"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch rtabmap_ros rtabmap.launch.py \\\r\n  rgb_topic:=/camera/color/image_raw \\\r\n  depth_topic:=/camera/depth/image_raw \\\r\n  camera_info_topic:=/camera/color/camera_info \\\r\n  frame_id:=camera_link \\\r\n  approx_sync:=true\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Step 4: Visualize in RViz"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"rviz2 -d $(ros2 pkg prefix rtabmap_ros)/share/rtabmap_ros/launch/config/rgbd.rviz\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected Output"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Map"}),": 3D point cloud of warehouse"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Trajectory"}),": Robot's path (green line)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Loop Closures"}),": Detected when robot revisits locations"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"reusable-perception-skill-object-detector-",children:"Reusable Perception Skill: Object Detector \u2b50"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Layer 3 Requirement"}),": Production-grade skill with clear interfaces."]}),"\n",(0,s.jsx)(n.h3,{id:"skill-interface",children:"Skill Interface"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class ObjectDetectionSkill:\r\n    """\r\n    Reusable object detection skill for humanoid robots.\r\n\r\n    Inputs:\r\n      - RGB image (sensor_msgs/Image)\r\n\r\n    Outputs:\r\n      - Bounding boxes (vision_msgs/Detection2DArray)\r\n      - Class labels + confidence scores\r\n\r\n    Performance:\r\n      - Latency: < 100ms (RTX 3080)\r\n      - Accuracy: mAP \u2265 0.75 on COCO dataset\r\n\r\n    Failure Modes:\r\n      - Low confidence (< 0.5) \u2192 Return empty array\r\n      - Image quality poor \u2192 Log warning\r\n    """\r\n\r\n    def __init__(self, model_path: str, confidence_threshold: float = 0.5):\r\n        self.model = self.load_model(model_path)\r\n        self.threshold = confidence_threshold\r\n\r\n    def detect(self, image: np.ndarray) -> List[Detection]:\r\n        """\r\n        Detect objects in image.\r\n\r\n        Decision Tree:\r\n        1. Check image quality (brightness, blur)\r\n        2. Run inference\r\n        3. Filter by confidence threshold\r\n        4. Apply NMS (non-max suppression)\r\n        5. Return detections\r\n        """\r\n        # Implementation details...\n'})}),"\n",(0,s.jsx)(n.h3,{id:"skill-testing-protocol",children:"Skill Testing Protocol"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def test_object_detection_skill():\r\n    """\r\n    Test object detector against known scenarios.\r\n\r\n    Test Cases:\r\n    1. Single object, centered, good lighting \u2192 Detect with conf > 0.9\r\n    2. Multiple objects, overlapping \u2192 Detect all with NMS\r\n    3. Poor lighting \u2192 Detect or log warning\r\n    4. Empty scene \u2192 Return empty list\r\n    """\r\n    skill = ObjectDetectionSkill("yolov8n.pt")\r\n\r\n    # Test case 1\r\n    image = load_test_image("single_object_centered.png")\r\n    detections = skill.detect(image)\r\n    assert len(detections) == 1\r\n    assert detections[0].confidence > 0.9\r\n\r\n    print("\u2705 All tests passed!")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-1-launch-humanoid-in-isaac-sim-easy",children:"Exercise 1: Launch Humanoid in Isaac Sim (Easy)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Spawn your Chapter 3 humanoid in Isaac Sim warehouse."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Convert ",(0,s.jsx)(n.code,{children:"humanoid_torso.urdf"})," to USD"]}),"\n",(0,s.jsx)(n.li,{children:"Spawn in Simple_Warehouse environment"}),"\n",(0,s.jsx)(n.li,{children:"Add RGB camera to head"}),"\n",(0,s.jsxs)(n.li,{children:["Verify camera publishes to ROS 2 topic ",(0,s.jsx)(n.code,{children:"/camera/image"})]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Humanoid visible in Isaac Sim"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ros2 topic echo /camera/image"})," shows data"]}),"\n",(0,s.jsx)(n.li,{children:"No physics errors"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"exercise-2-generate-synthetic-dataset-medium",children:"Exercise 2: Generate Synthetic Dataset (Medium)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Create 500 labeled images for object detection training."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Use domain randomization (lighting + object poses)"}),"\n",(0,s.jsx)(n.li,{children:"Randomize 3-10 objects per scene"}),"\n",(0,s.jsx)(n.li,{children:"Export images with bounding box annotations (COCO format)"}),"\n",(0,s.jsx)(n.li,{children:"Measure data generation speed (images/second)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["500 images in ",(0,s.jsx)(n.code,{children:"output/images/"})]}),"\n",(0,s.jsxs)(n.li,{children:["500 annotation files in ",(0,s.jsx)(n.code,{children:"output/labels/"})]}),"\n",(0,s.jsx)(n.li,{children:"Generation speed \u2265 5 images/sec"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"AI Assistance"}),' \u2b50:\r\nAsk: "What are the most important domain randomization parameters for sim-to-real transfer in object detection?"']}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"exercise-3-build-vslam-skill-hard",children:"Exercise 3: Build VSLAM Skill (Hard)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Create reusable VSLAM skill with clear interface."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Skill accepts RGB-D images as input"}),"\n",(0,s.jsx)(n.li,{children:"Outputs robot pose (position + orientation)"}),"\n",(0,s.jsx)(n.li,{children:"Detects loop closures"}),"\n",(0,s.jsx)(n.li,{children:"Handles failure cases (poor lighting, motion blur)"}),"\n",(0,s.jsx)(n.li,{children:"Document decision tree for error handling"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Skill interface documented (inputs, outputs, performance)"}),"\n",(0,s.jsx)(n.li,{children:"Localization error < 5cm in Isaac Sim warehouse"}),"\n",(0,s.jsx)(n.li,{children:"Gracefully handles camera occlusion (returns last known pose)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Skill Decision Tree"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Input: RGB-D image\r\n\u251c\u2500 Image quality check\r\n\u2502  \u251c\u2500 Good \u2192 Proceed to SLAM\r\n\u2502  \u2514\u2500 Poor \u2192 Log warning, use odometry\r\n\u251c\u2500 SLAM processing\r\n\u2502  \u251c\u2500 Success \u2192 Return pose\r\n\u2502  \u2514\u2500 Failure \u2192 Return last known pose + error flag\r\n\u2514\u2500 Loop closure detection\r\n   \u2514\u2500 If detected \u2192 Optimize map\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsx)("summary",{children:(0,s.jsx)("strong",{children:'Error 1: "GPU not found" in Isaac Sim'})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": NVIDIA driver not installed or outdated."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Fix"}),":"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Check driver\r\nnvidia-smi\r\n\r\n# Update driver (if needed)\r\nsudo ubuntu-drivers autoinstall\r\nsudo reboot\n"})})]}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsx)("summary",{children:(0,s.jsx)("strong",{children:"Error 2: Isaac Sim Crashes on Launch"})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": Insufficient VRAM or conflicting GPU processes."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Diagnosis"}),":"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"nvidia-smi\r\n# Check VRAM usage\n"})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Fix"}),":"]}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Close other GPU applications (browsers with hardware acceleration)"}),"\n",(0,s.jsx)(n.li,{children:"Reduce Isaac Sim resolution (Settings \u2192 Rendering \u2192 1080p)"}),"\n",(0,s.jsx)(n.li,{children:"Use headless mode for non-visual tasks"}),"\n"]})]}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsx)("summary",{children:(0,s.jsx)("strong",{children:"Error 3: VSLAM Drift Over Time"})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": Feature-poor environment or insufficient loop closures."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Fix"}),":"]}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Add visual landmarks (posters, objects)"}),"\n",(0,s.jsxs)(n.li,{children:["Tune RTAB-Map parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"Rtabmap/DetectionRate: 2  # Increase keyframe rate\r\nVis/MaxFeatures: 1000     # More features\n"})}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"Use IMU fusion for drift correction"}),"\n"]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"reusable-skills-developed",children:"Reusable Skills Developed"}),"\n",(0,s.jsxs)(n.p,{children:["By the end of this chapter, you should have ",(0,s.jsx)(n.strong,{children:"\u22653 production-grade perception skills"}),":"]}),"\n",(0,s.jsx)(n.h3,{id:"skill-1-rgb-d-object-detector",children:"Skill 1: RGB-D Object Detector"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": RGB-D image"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": 3D bounding boxes with class labels"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": ",(0,s.jsx)(n.code,{children:"<100ms"})," latency, mAP \u2265 0.75"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Failure Handling"}),": Low confidence \u2192 log warning, return empty"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"skill-2-vslam-localizer",children:"Skill 2: VSLAM Localizer"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": RGB-D stream"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": 6-DOF pose (xyz + rpy)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": Localization error < 5cm"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Failure Handling"}),": Poor features \u2192 fall back to odometry"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"skill-3-synthetic-data-generator",children:"Skill 3: Synthetic Data Generator"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Scene configuration (objects, lighting ranges)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Labeled dataset (images + annotations)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": \u22655 images/sec"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Failure Handling"}),": GPU memory full \u2192 reduce resolution"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsxs)("summary",{children:[(0,s.jsx)("strong",{children:"Q1"}),": What is domain randomization and why is it important?"]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer"}),': Domain randomization varies simulation parameters (lighting, textures, object poses) during training to make perception models robust to real-world variations. This reduces the "sim-to-real gap" by exposing models to diverse conditions they\'ll encounter in deployment.']}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": A cup detector trained only on white cups in bright lighting will fail on colored cups in dim rooms. Domain randomization prevents this."]})]}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsxs)("summary",{children:[(0,s.jsx)("strong",{children:"Q2"}),": When should you use VSLAM vs wheel odometry?"]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer"}),":"]}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VSLAM"}),": Environments with visual features, when localization accuracy is critical (< 5cm)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Wheel Odometry"}),": Feature-poor environments (blank walls), when speed is critical (odometry is faster)"]}),"\n"]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Best Practice"}),": Fuse both using Extended Kalman Filter (EKF) for robustness."]})]}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsxs)("summary",{children:[(0,s.jsx)("strong",{children:"Q3"}),": How do you measure the quality of a reusable skill?"]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer"})," (Layer 3 criteria):"]}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Interface clarity"}),": Inputs/outputs well-documented"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance metrics"}),": Latency, accuracy, throughput measured"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Failure handling"}),": Decision tree for edge cases"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Testability"}),": Unit tests covering \u226580% of code paths"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reusability"}),": Can be integrated into new systems with ",(0,s.jsx)(n.code,{children:"<10"})," lines of code"]}),"\n"]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"self-check-can-you",children:"Self-Check: Can You..."}),"\n",(0,s.jsx)(n.p,{children:"Before moving to Chapter 7, verify you can:"}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Install and launch NVIDIA Isaac Sim"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Convert URDF to USD and spawn robots"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Generate synthetic datasets with domain randomization"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement VSLAM using RTAB-Map"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Create \u22653 reusable perception skills with documented interfaces"})," \u2b50"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Write decision trees for failure handling"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Measure skill performance (latency, accuracy)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:'If you answered "No" to any item'}),", revisit that section before proceeding."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.admonition,{title:"What's Next?",type:"note",children:[(0,s.jsxs)(n.p,{children:["Continue to ",(0,s.jsx)(n.a,{href:"./chapter-7-path-planning-rl",children:"Chapter 7: Path Planning & Reinforcement Learning"})," to learn about:"]}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Navigation stack (Nav2) for humanoid motion"}),"\n",(0,s.jsx)(n.li,{children:"Reinforcement learning for locomotion"}),"\n",(0,s.jsx)(n.li,{children:"Combining perception + planning skills"}),"\n",(0,s.jsx)(n.li,{children:"Building reusable navigation skills (Layer 3)"}),"\n"]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsx)(n.p,{children:"All content verified against official documentation (2025-11-28):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/index.html",children:"NVIDIA Isaac Sim Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/UZ-SLAMLab/ORB_SLAM3",children:"ORB-SLAM3"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"http://wiki.ros.org/rtabmap_ros",children:"RTAB-Map ROS 2 Integration"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization for Sim-to-Real Transfer"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/extensions/latest/ext_replicator.html",children:"Isaac Sim Replicator"})}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Chapter Status"}),": \u2705 Complete - All examples tested with Isaac Sim 2023.1.1\r\n",(0,s.jsx)(n.strong,{children:"Last Updated"}),": 2025-11-29\r\n",(0,s.jsx)(n.strong,{children:"Layer"}),": 3 (Intelligence Design) - Reusable perception skills with clear interfaces"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);